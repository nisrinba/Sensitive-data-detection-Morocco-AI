DÃ©tection Automatique des DonnÃ©es Sensibles (Loi 09-08)

## Description

Ce projet a pour objectif de concevoir un systÃ¨me de **dÃ©tection automatique des donnÃ©es sensibles** dans des jeux de donnÃ©es mÃ©dicaux, en conformitÃ© avec la **loi marocaine 08-09** sur la protection des donnÃ©es Ã  caractÃ¨re personnel.  
Il repose sur lâ€™utilisation de plusieurs algorithmes dâ€™apprentissage automatique, comparÃ©s selon diffÃ©rents critÃ¨res de performance.

---

## Contexte LÃ©gal

La loi 08-09 stipule que les donnÃ©es dites Â« sensibles Â» incluent :
- Les informations mÃ©dicales
- Les donnÃ©es dâ€™identitÃ© (Ã¢ge, nom, date de naissanceâ€¦)
- Les donnÃ©es biomÃ©triques ou gÃ©nÃ©tiques
- Les numÃ©ros dâ€™identification (dossier mÃ©dical, tÃ©lÃ©phoneâ€¦)
- Les informations relatives Ã  la vie privÃ©e

Dans ce projet, un individu est considÃ©rÃ© comme Â« sensible Â» sâ€™il :
- A un Ã¢ge supÃ©rieur Ã  **65 ans**
- Ou un **montant de facturation** supÃ©rieur au troisiÃ¨me quartile

---

## DonnÃ©es

- **Source :** [Kaggle - Healthcare Dataset](https://www.kaggle.com/datasets/prasad22/healthcare-dataset)
- **Format :** CSV (~1000 enregistrements)
- **PrÃ©traitement :**
  - Nettoyage des doublons
  - Standardisation des noms de colonnes
  - Encodage des variables catÃ©gorielles
  - CrÃ©ation de la variable cible `is_sensitive`
  - Gestion du dÃ©sÃ©quilibre avec **SMOTE**

---

## Algorithmes utilisÃ©s

| ModÃ¨le                | Justification principale |
|-----------------------|--------------------------|
| Random Forest         | Robuste, interprÃ©table, efficace sur donnÃ©es dÃ©sÃ©quilibrÃ©es |
| XGBoost               | TrÃ¨s performant, adaptÃ© aux donnÃ©es dÃ©sÃ©quilibrÃ©es |
| SVM                   | Efficace pour la sÃ©paration complexe des classes |
| RÃ©gression Logistique | Baseline simple et interprÃ©table |
| Naive Bayes           | Rapide et efficace sur des jeux de petite taille |

Tous les modÃ¨les sont intÃ©grÃ©s dans un **pipeline** incluant :
- Normalisation (`StandardScaler`)
- SurÃ©chantillonnage (`SMOTE`)
- EntraÃ®nement et Ã©valuation

---

## Ã‰valuation des performances

Les modÃ¨les sont Ã©valuÃ©s sur un jeu de test via les mÃ©triques suivantes :
- **Accuracy**
- **PrÃ©cision**
- **Rappel**
- **F1-score**
- **AUC ROC**

### RÃ©sultats obtenus (extrait) :

| ModÃ¨le                | Accuracy | PrÃ©cision | Rappel | F1-score | AUC |
|-----------------------|----------|-----------|--------|----------|-----|
| Random Forest         | 0.823    | 1.000     | 0.625  | 0.769    | 0.825 |
| XGBoost               | 0.823    | 0.999     | 0.625  | 0.769    | 0.818 |
| SVM                   | 0.792    | 0.867     | 0.659  | 0.749    | 0.813 |
| Naive Bayes           | 0.738    | 0.724     | 0.716  | 0.720    | 0.814 |
| RÃ©gression Logistique | 0.724    | 0.696     | 0.733  | 0.714    | 0.815 |

---

## Recommandations

- **ModÃ¨les globaux recommandÃ©s :** `Random Forest`, `XGBoost`
- **ModÃ¨les Ã  privilÃ©gier pour un meilleur rappel :** `Naive Bayes`, `RÃ©gression Logistique`
- **Compromis Ã©quilibrÃ© :** `SVM`

---

## Visualisations

- **Matrice de confusion**
- **Courbes ROC comparÃ©es**
- **Importance des variables (Random Forest)**
- **Barres de comparaison des performances**

---

## PrÃ©requis

- Python 3.7+
- BibliothÃ¨ques :
  - `pandas`, `numpy`
  - `matplotlib`, `seaborn`
  - `scikit-learn`
  - `xgboost`
  - `imbalanced-learn`

> Installer les dÃ©pendances :
```bash
pip install pandas numpy matplotlib seaborn scikit-learn xgboost imbalanced-learn
```

---



---

## ğŸ“š RÃ©fÃ©rences

- [Loi 08-09 sur la protection des donnÃ©es personnelles (CNDP)](https://www.cndp.ma)
- [Kaggle Dataset utilisÃ©](https://www.kaggle.com/datasets/prasad22/healthcare-dataset)
